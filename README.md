# Build a RAG Document Chatbot using Llama LLM Models
## Overview
A Retrieval-Augmented Generation (RAG) chatbot powered by the Ollama platform, designed to deliver precise and context-aware responses by combining document retrieval with generative AI. The system efficiently indexes and retrieves relevant documents, seamlessly integrating them into AI-generated conversational responses, making it an ideal solution for knowledge management and customer support applications.
## Architecture
![image](https://github.com/user-attachments/assets/636f692a-dcaa-4ce4-b780-1b1f9ef5fd12)
## Install the Requirements
```
pip3 install -r requirements
```
## Run the Flask Application
```
python3 app.py
```
## Usage
### Create a new Session
![image](https://github.com/user-attachments/assets/ae126f34-4d77-4033-a568-1a697f5e4c09)
### Open the sessions created
![image](https://github.com/user-attachments/assets/0f6e2b07-3f95-4656-bb2a-4d157eafad02)
### Upload and Process the document
Wait until the document finished process
![image](https://github.com/user-attachments/assets/2ec76c5c-acfe-4d56-aa7b-ccdf6d4f9597)
### Start Chat with your document
![image](https://github.com/user-attachments/assets/e000ced7-6c43-4dc4-bc16-b42663fa7661)





